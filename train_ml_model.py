#!/usr/bin/env python3
"""
train_ml_model.py - æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
ç¿Œé€±ã®æ ªä¾¡ä¸Šæ˜‡ç¢ºç‡ã‚’äºˆæ¸¬ã™ã‚‹LightGBMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
"""

import os
import json
import pathlib
import numpy as np
import pandas as pd
import vectorbt as vbt
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.model_selection import train_test_split
import lightgbm as lgb
import joblib
import settings as cfg


def create_features(close_prices, volume_data):
    """
    MLç”¨ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
    
    Args:
        close_prices: çµ‚å€¤ãƒ‡ãƒ¼ã‚¿ (DataFrame)
        volume_data: å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ (DataFrame)
    
    Returns:
        features_df: ç‰¹å¾´é‡DataFrame
    """
    features_list = []
    
    for ticker in close_prices.columns:
        if ticker not in volume_data.columns:
            continue
            
        price = close_prices[ticker].dropna()
        volume = volume_data[ticker].dropna()
        
        # æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿æ•°ãƒã‚§ãƒƒã‚¯
        if len(price) < 250:  # ç´„1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿
            continue
            
        # ç‰¹å¾´é‡ç”Ÿæˆ
        feature_data = pd.DataFrame(index=price.index)
        
        # 1. ä¾¡æ ¼é–¢é€£ã®ç‰¹å¾´é‡
        feature_data['price_ratio_5'] = price / price.shift(5)  # 5æ—¥å‰æ¯”
        feature_data['price_ratio_10'] = price / price.shift(10)  # 10æ—¥å‰æ¯”
        feature_data['price_ratio_20'] = price / price.shift(20)  # 20æ—¥å‰æ¯”
        
        # 2. ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢
        sma_20 = price.rolling(20).mean()
        sma_50 = price.rolling(50).mean()
        feature_data['price_vs_sma20'] = price / sma_20
        feature_data['price_vs_sma50'] = price / sma_50
        feature_data['sma20_vs_sma50'] = sma_20 / sma_50
        
        # 3. RSI
        rsi = vbt.RSI.run(price, window=14).rsi
        if isinstance(rsi, pd.DataFrame):
            rsi = rsi.iloc[:, 0]
        feature_data['rsi'] = rsi
        
        # 4. å‡ºæ¥é«˜é–¢é€£
        vol_sma_20 = volume.rolling(20).mean()
        feature_data['volume_ratio'] = volume / vol_sma_20
        
        # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        returns = price.pct_change()
        feature_data['volatility_20'] = returns.rolling(20).std()
        
        # 6. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
        feature_data['momentum_10'] = (price / price.shift(10) - 1) * 100
        feature_data['momentum_20'] = (price / price.shift(20) - 1) * 100
        
        # 7. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆï¼ˆç¿Œé€±ã®ä¾¡æ ¼ä¸Šæ˜‡åˆ¤å®šï¼‰
        # é€±æ¬¡ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        weekly_price = price.resample('W-FRI').last()
        target = (weekly_price.shift(-1) > weekly_price).astype(int)
        
        # ç‰¹å¾´é‡ã‚‚é€±æ¬¡ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        weekly_features = feature_data.resample('W-FRI').last()
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆã‚ã›ã‚‹
        aligned_target = target.reindex(weekly_features.index)
        
        # æ¬ æå€¤ã‚’é™¤å»
        valid_idx = weekly_features.dropna().index.intersection(aligned_target.dropna().index)
        if len(valid_idx) < 50:  # æœ€ä½50é€±é–“ã®ãƒ‡ãƒ¼ã‚¿
            continue
            
        # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        for date in valid_idx:
            row = weekly_features.loc[date].copy()
            row['ticker'] = ticker
            row['date'] = date
            row['target'] = aligned_target.loc[date]
            features_list.append(row)
    
    if not features_list:
        raise ValueError("ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    return pd.DataFrame(features_list)


def train_model():
    """
    æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    """
    print("ğŸš€ ML ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    pathlib.Path(cfg.DATA_DIR).mkdir(exist_ok=True)
    
    # ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    close_path = f"{cfg.DATA_DIR}/close.csv"
    volume_path = f"{cfg.DATA_DIR}/volume.csv"
    
    if not os.path.exists(close_path) or not os.path.exists(volume_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {close_path}, {volume_path}")
        print("ã¾ãšdata_download.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    close_prices = pd.read_csv(close_path, index_col=0, parse_dates=True)
    volume_data = pd.read_csv(volume_path, index_col=0, parse_dates=True)
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(close_prices)} æ—¥åˆ†, {len(close_prices.columns)} éŠ˜æŸ„")
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    print("ğŸ”§ ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
    features_df = create_features(close_prices, volume_data)
    
    print(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(features_df)} ã‚µãƒ³ãƒ—ãƒ«")
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
    feature_cols = [col for col in features_df.columns if col not in ['ticker', 'date', 'target']]
    X = features_df[feature_cols]
    y = features_df['target']
    
    # æ¬ æå€¤ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯
    X = X.fillna(0)
    
    print(f"ğŸ“ˆ ç‰¹å¾´é‡æ•°: {len(feature_cols)}, ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
    print(f"ğŸ“Š ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # LightGBMãƒ¢ãƒ‡ãƒ«è¨“ç·´
    print("ğŸ¯ LightGBMè¨“ç·´ä¸­...")
    
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': 0,
        'random_state': 42
    }
    
    model = lgb.train(
        params,
        train_data,
        valid_sets=[valid_data],
        num_boost_round=1000,
        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)]
    )
    
    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    y_pred = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred_binary = (y_pred > 0.5).astype(int)
    
    auc_score = roc_auc_score(y_test, y_pred)
    accuracy = (y_pred_binary == y_test).mean()
    
    print(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ:")
    print(f"   AUC Score: {auc_score:.4f}")
    print(f"   Accuracy: {accuracy:.4f}")
    
    # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
    print("\nğŸ“‹ åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
    print(classification_report(y_test, y_pred_binary))
    
    # ç‰¹å¾´é‡é‡è¦åº¦
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importance()
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ” ç‰¹å¾´é‡é‡è¦åº¦ (Top 10):")
    print(feature_importance.head(10))
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_path = f"{cfg.DATA_DIR}/ml_model.joblib"
    joblib.dump(model, model_path)
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")
    
    # ç‰¹å¾´é‡åã‚’ä¿å­˜
    feature_names_path = f"{cfg.DATA_DIR}/feature_names.json"
    with open(feature_names_path, 'w') as f:
        json.dump(feature_cols, f)
    print(f"ğŸ“ ç‰¹å¾´é‡åä¿å­˜å®Œäº†: {feature_names_path}")
    
    print("âœ… ML ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†!")
    return model


if __name__ == "__main__":
    train_model()